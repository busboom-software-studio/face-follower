{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e64780",
   "metadata": {},
   "source": [
    "# Real-Time Red Object Detection with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c663f",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447a335",
   "metadata": {},
   "source": [
    "This notebook was created by [Jupyter AI](https://github.com/jupyterlab/jupyter-ai) with the following prompt:\n",
    "\n",
    "> /generate show me an example of python opencv code that reads from the web camera, finds a red object in the image and draws a box around the object. The program should open a window and show the web camera image with a box around the object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a8701",
   "metadata": {},
   "source": [
    "This Jupyter notebook serves as a comprehensive guide to using OpenCV with Python for real-time object detection, specifically focusing on identifying and highlighting red objects from a web camera feed. The notebook begins with importing essential libraries such as OpenCV and NumPy. It then proceeds to initialize the web camera for video capture using OpenCV's VideoCapture class. A dedicated function is created to process each frame, converting the color space and applying thresholding techniques to isolate red-colored objects. The detected objects are then highlighted by drawing bounding boxes around them using OpenCV's rectangle function. The notebook sets up a loop to continuously read frames from the web camera, apply the red object detection function, and display the processed frames in a window using OpenCV's imshow function. Finally, it ensures proper cleanup by releasing the camera and closing all OpenCV windows upon termination of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebe3d9",
   "metadata": {},
   "source": [
    "## Initializing the Web Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179c129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b88eae1f-4394-4c2e-ab37-bdd5676a92d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 17:07:07.160 Python[75401:19346797] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available camera indices: [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: out device of bound (0-1): 2\n",
      "OpenCV: camera failed to properly initialize!\n",
      "OpenCV: out device of bound (0-1): 3\n",
      "OpenCV: camera failed to properly initialize!\n",
      "OpenCV: out device of bound (0-1): 4\n",
      "OpenCV: camera failed to properly initialize!\n",
      "OpenCV: out device of bound (0-1): 5\n",
      "OpenCV: camera failed to properly initialize!\n",
      "OpenCV: out device of bound (0-1): 6\n",
      "OpenCV: camera failed to properly initialize!\n",
      "OpenCV: out device of bound (0-1): 7\n",
      "OpenCV: camera failed to properly initialize!\n",
      "OpenCV: out device of bound (0-1): 8\n",
      "OpenCV: camera failed to properly initialize!\n",
      "OpenCV: out device of bound (0-1): 9\n",
      "OpenCV: camera failed to properly initialize!\n"
     ]
    }
   ],
   "source": [
    "def list_available_cameras(max_cameras=10):\n",
    "    available_cameras = []\n",
    "    for index in range(max_cameras):\n",
    "        cap = cv2.VideoCapture(index)\n",
    "        if cap.isOpened():\n",
    "            available_cameras.append(index)\n",
    "            cap.release()\n",
    "    return available_cameras\n",
    "\n",
    "# List all available cameras\n",
    "available_cameras = list_available_cameras()\n",
    "print(\"Available camera indices:\", available_cameras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3035e",
   "metadata": {},
   "source": [
    "## Defining the Red Object Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b50fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_red_objects(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red_1 = np.array([0, 120, 70])\n",
    "    upper_red_1 = np.array([10, 255, 255])\n",
    "    lower_red_2 = np.array([170, 120, 70])\n",
    "    upper_red_2 = np.array([180, 255, 255])\n",
    "    \n",
    "    mask1 = cv2.inRange(hsv, lower_red_1, upper_red_1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red_2, upper_red_2)\n",
    "    \n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd8c81d",
   "metadata": {},
   "source": [
    "## Drawing the Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e52abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00dc4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(frame, mask):\n",
    "    \"\"\"\n",
    "    Find contours in the mask and draw bounding boxes around the detected red objects in the frame.\n",
    "        Parameters:\n",
    "    - frame: The current frame from the web camera.\n",
    "    - mask: The mask of the detected red color from the frame.\n",
    "    Returns:\n",
    "    - The frame with bounding boxes drawn around detected red objects.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70e0ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in a real-time video capturing loop\n",
    "# Uncomment and run this part in the main section of your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f054aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "#     hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "#     lower_red1 = np.array([0, 120, 70])\n",
    "#     upper_red1 = np.array([10, 255, 255])\n",
    "#     mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "#     lower_red2 = np.array([170, 120, 70])\n",
    "#     upper_red2 = np.array([180, 255, 255])\n",
    "#     mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "#     mask = mask1 + mask2\n",
    "#     frame_with_boxes = draw_bounding_boxes(frame, mask)\n",
    "#     cv2.imshow('Red Object Detection', frame_with_boxes)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc1a16",
   "metadata": {},
   "source": [
    "## Displaying the Video Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8640d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2bfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_red_object(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red1 = np.array([0, 120, 70])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    \n",
    "    lower_red2 = np.array([170, 120, 70])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    \n",
    "    mask = mask1 + mask2\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d15c5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ccbc4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 17:07:11.006 Python[75401:19346797] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "    \n",
    "    processed_frame = detect_red_object(frame)\n",
    "    cv2.imshow('Red Object Detection', processed_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370597ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcbaae7",
   "metadata": {},
   "source": [
    "## Releasing the Camera and Closing Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0583fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "534d95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_resources(cap):\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Camera released and all windows closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
